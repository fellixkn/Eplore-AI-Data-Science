{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Practical MCQ: NLP and classification\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this train, we'll explore and evaluate different machine learning classifiers through various tasks like model fitting, parameter tuning, and performance comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "\n",
    "- Utilise vectorisation techniques to process textual data.\n",
    "- Implement logistic regression and measure its accuracy.\n",
    "- Determine optimal model parameters using grid search.\n",
    "- Interpret the output of machine learning models using confusion matrices.\n",
    "- Analyse the performance of classifiers with precision-recall metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8863c65d",
   "metadata": {},
   "source": [
    "> ⚠️ Please note that the multiple choices to all questions are not included in this notebook; they are available exclusively on the MCQ webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b7683",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecec55",
   "metadata": {},
   "source": [
    "What does the `CountVectorizer` output `X` represent in the code snippet below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc759b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample text data\n",
    "data = [\"Machine learning is fascinating.\", \"Natural language processing and machine learning are closely linked.\"]\n",
    "\n",
    "# Initialise the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "X = vectorizer.fit_transform(data)\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ccb80d",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Modify the code below to compute and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ad301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialise the Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc9de7",
   "metadata": {},
   "source": [
    "What is the accuracy of the logistic regression model on the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd508e27",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "What is the value of True Positive (TP) in the confusion matrix generated by the RandomForestClassifier below? Modify the code to print the value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Generate synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25577a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93542c5b",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "What is the best value of the parameter 'C' for the SVC according to the grid search? Modify the code to print the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Load a dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Initialize an SVC (Support Vector Classifier) with a linear kernel\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Define parameter range for C (regularization parameter)\n",
    "param_grid = {'C': np.logspace(-3, 3, 7)}\n",
    "\n",
    "# Setup the grid search with cross-validation\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a41522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98217731",
   "metadata": {},
   "source": [
    "## Question 5 \n",
    "\n",
    "Which code snippet can be used to fill in the missing lines of code to train the SVM classifier, predict the test set results, and print the classification report?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac91d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the SVM classifier with a radial basis function kernel\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "# [Your Code Here] - Line to add for fitting the model\n",
    "\n",
    "# Predict the test set results\n",
    "# [Your Code Here] - Line to add for making predictions\n",
    "\n",
    "# Generate and print the classification report\n",
    "# [Your Code Here] - Line to add for printing the classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e875cb9",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Given the code below, your task is to select the function from the options provided that correctly completes the task by:\n",
    "\n",
    "i) Creating a function that determines which classifier (KNN or Naive Bayes) has a higher F1 score, or if they have equal scores.\n",
    "\n",
    "ii) Printing the name of the classifier along with its F1 score in the format: 'ClassifierName has the higher F1 score of Score' or 'Both classifiers have the same F1 score of Score'.\n",
    "\n",
    "iii) Executing the function.\n",
    "\n",
    "Select the appropriate code snippet from the options below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize KNN and Naive Bayes classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train both classifiers on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set results for both classifiers\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Calculate F1 scores for both classifiers\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "\n",
    "# [Your Code Here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9667f9",
   "metadata": {},
   "source": [
    "## Question  7 \n",
    "\n",
    "Which of the following options will complete the missing code lines to:\n",
    "\n",
    "i) train the MLPClassifier, \n",
    "\n",
    "ii) predict the test set labels,\n",
    "\n",
    "iii) count the number of misclassified samples,\n",
    "\n",
    "iv) call the function to print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Generate a two-moon dataset\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialise the MLPClassifier with one hidden layer with 10 neurons\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)\n",
    "\n",
    "# [Your Code Here] - Train the MLPClassifier on the scaled training data\n",
    "\n",
    "# [Your Code Here] - Predict the labels for the scaled test data\n",
    "\n",
    "# [Your Code Here] - Print the number of misclassified samples in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8065ab7",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "Before running the final line of the code in the snippet below to fit the `grid_search` object, you are asked to perform the following tasks directly in the code:\n",
    "\n",
    "1. Modify the `param_grid` to include a new parameter: `'max_features'` with values ranging from 1 to 4.\n",
    "2. Fit the `grid_search` to the training data.\n",
    "3. After fitting, extract and print the best parameter combination and the corresponding cross-validation score.\n",
    "\n",
    "Which of the following options correctly completes these tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba25b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setup a basic decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define a parameter grid over which to optimize the decision tree\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 10, 20]\n",
    "}\n",
    "\n",
    "# Setup the GridSearchCV\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b112d7e",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "You are fine-tuning a decision tree classifier for a marketing dataset. To prevent overfitting and ensure robust generalisability, you must adjust the depth of the decision tree after its initialisation but before it is fitted with data. Considering the decision tree `dt` has already been initialised with a random state, which of the following is the correct way to modify the tree's maximum depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38372bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialise decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# [Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537192ee",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "Suppose you are analysing the performance of a new email spam detection system using precision and recall. You have already computed these metrics, and you are about to explore their trade-offs to optimise the classifier's threshold. Given the code snippet below, identify the correct function call that would allow you to adjust and visualise the precision-recall trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic data for binary classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train a RandomForest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_scores = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# [Your Code Here] - Generate precision and recall values for various thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198463ec",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "You are tasked with enhancing the robustness of a logistic regression model by incorporating feature scaling. You're currently working with a dataset that has significantly varying scales among its features, which can affect the model's performance. Below is a preliminary setup for the logistic regression model. Identify the correct sequence of steps to integrate feature scaling into the modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# [Your Code Here] - Apply feature scaling to the training data\n",
    "# [Your Code Here] - Fit the model on the scaled training data\n",
    "# [Your Code Here] - Apply the same scaling to the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9ab5e",
   "metadata": {},
   "source": [
    "# Question 12\n",
    "\n",
    "You are fine-tuning a support vector machine (SVM) classifier to categorise images based on their content. The dataset consists of various animal images, and you suspect that different kernel functions might yield better classification accuracy. You decide to test which SVM kernel—linear or radial basis function (RBF)—works best for your specific dataset. Below is your initial code setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc8d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load a dataset of digit images\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize two SVM classifiers, one with a linear kernel and another with an RBF kernel\n",
    "svm_linear = SVC(kernel='linear')\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "# [Your Code Here] - Train both classifiers on the training data\n",
    "# [Your Code Here] - Predict the test set results with both classifiers\n",
    "# [Your Code Here] - Calculate and print the accuracy scores for both classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097f7ae",
   "metadata": {},
   "source": [
    "Which of the following options correctly completes the task of training both SVM classifiers, predicting the test set results, and calculating the accuracy for each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f3dfa",
   "metadata": {},
   "source": [
    "## Question 13 \n",
    "\n",
    "You are currently evaluating two classifiers, K-Nearest Neighbours (KNN) and Naive Bayes, for a project that involves classifying texts into different categories based on their content. To finalise your model selection, you decide to visually compare their performance using a bar chart. Below is the setup for calculating the accuracy of both models on your dataset. Complete the code by adding the necessary lines to plot the accuracies in a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "data = fetch_20newsgroups(subset='all')\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorise text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialise classifiers\n",
    "knn = KNeighborsClassifier()\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Train classifiers\n",
    "knn.fit(X_train_tfidf, y_train)\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "knn_accuracy = accuracy_score(y_test, knn.predict(X_test_tfidf))\n",
    "nb_accuracy = accuracy_score(y_test, nb.predict(X_test_tfidf))\n",
    "\n",
    "# [Your code here] - Plot the accuracies in a bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca8e77",
   "metadata": {},
   "source": [
    "Which snippet of code will correctly plot the accuracies of KNN and Naive Bayes classifiers in a bar chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db7298",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "You are tasked with evaluating a simple binary classification model using a confusion matrix. The dataset involves predicting whether a given email is spam or not. To better understand the model's performance, you plan to extract specific metrics from the confusion matrix, specifically True Positives (TP) and False Positives (FP). Below is your initial code setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# [Your code here] - Extract and print True Positives and False Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3d05",
   "metadata": {},
   "source": [
    "Which snippet of code correctly extracts and prints the True Positives (TP) and False Positives (FP) from the confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54632b17",
   "metadata": {},
   "source": [
    "Which snippet of code correctly completes the setup to create a pipeline including `PolynomialFeatures` and `LogisticRegression`, fits it on the training data, and makes predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3781c44",
   "metadata": {},
   "source": [
    "## Question 15 (Medium)\n",
    "\n",
    "You are refining a logistic regression model to predict customer churn. The dataset includes various customer interaction metrics. To enhance your model, explore how polynomial features can improve prediction accuracy. This approach allows the model to capture complex interactions between variables. \n",
    "\n",
    "Here is your setup: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08305212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate synthetic data for binary classification\n",
    "X, y = make_classification(n_samples=1000, n_features=3, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply polynomial features manually\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a2e94",
   "metadata": {},
   "source": [
    "What is the correct procedure to fit a logistic regression model on the training data after transforming it with polynomial features, and how should predictions be made on the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
